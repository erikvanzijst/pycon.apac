<!doctype html>
<html lang="en">

	<head>
		<meta charset="utf-8">

		<title>PyCon AU -- Interrupt-Driven Programming</title>

		<meta name="description" content="This talk explores the challenges of ensuring responsiveness of applications under varying conditions like suddenly increased load, code regressions and problematic user data that reveal code paths with unusually high time complexity.">
		<meta name="author" content="Erik van Zijst">

		<meta name="apple-mobile-web-app-capable" content="yes" />
		<meta name="apple-mobile-web-app-status-bar-style" content="black-translucent" />

		<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">

		<link rel="stylesheet" href="css/reveal.min.css">
		<link rel="stylesheet" href="css/theme/default.css" id="theme">

		<!-- For syntax highlighting -->
		<link rel="stylesheet" href="lib/css/github.css">

		<!-- If the query includes 'print-pdf', use the PDF print sheet -->
		<script>
			document.write( '<link rel="stylesheet" href="css/print/' + ( window.location.search.match( /print-pdf/gi ) ? 'pdf' : 'paper' ) + '.css" type="text/css" media="print">' );
		</script>

		<!--[if lt IE 9]>
		<script src="lib/js/html5shiv.js"></script>
		<![endif]-->
	</head>

	<body>
		<div class="reveal">
			<!-- Any section element inside of this container is displayed as a slide -->
			<div class="slides">

      <section>
        <h1>Interrupt-driven programming</h1>

        <div id="erik-van-zijst">
          <p>Erik van Zijst</p>
          <p>
            <a href="https://twitter.com/erikvanzijst">@erikvanzijst</a>
          </p>
          <p>
            <a href="https://bitbucket.org/evzijst">bitbucket.org/evzijst</a>
          </p>
        </div>
        
        <aside data-markdown class="notes">
          G'day everybody, I'm Erik, I work at Atlassian where I'm a dev on
          Bitbucket and I want to talk a bit about the importance of responsive
          code and share some techniques that can help with that.
        </aside>
      </section>


      <section>
        <h2>
          <img
            src="tweet.png" style="font-size: 75.96px; width: 574px;">
        </h2>
        <aside data-markdown class="notes">
          Recently this tweet showed up on my timeline, which took me by
          surprise. This being a tweet, there was of course no context or detail
          whatsoever and while I bet he wasn't lying, it left me guessing what
          this Stephen had been looking at.
        </aside>
      </section>


      <section>
        <h2>Really?</h2>
        <div>
          <img src="bitbucket_performance.png" style="height: 285px;">
        </div>
        <div>
          <img src="github_performance.png" style="height: 170px;">
        </div>
        <div>123ms vs 139ms &mdash; Averages are misleading</div>

        <aside data-markdown class="notes">
          A quick comparison of the 2 sites' average response time provides no
          basis for the big discrepancy.
          
          I had a closer look and learned that Stephen works for a company that
          builds a product that integrates with both Bitbucket and GitHub. It
          also showed that their integration relies on a small number of APIs,
          of which one performs exceptionally poorly.

          Due to the APIs low traffic, its poor performance has almost no affect
          on the average. Our busiest pages and APIs have been also been tuned
          the most, which goes to show that averages are a misleading
          metric. It's a number that gives us a false sense of accomplishment but
          which says nothing at all about the usability of the service. Just ask
          Stephen.
          
          So what he was seeing was real, but wasn't representative for the service
          as a whole. He was just unlucky that he had to use such a crappy
          API endpoint.
        </aside>
      </section>


      <section>
          <h3>
            Slow requests have a big impact
          </h3>
        <div>

          <ul>
            <li class="fragment">Frustrate users, timeouts</li>
            <li class="fragment">Break API clients</li>
            <li class="fragment">Rants on Twitter</li>
          </ul>
          <div style="text-align: left;">
            <br>
          </div>
          <div class="fragment" style="text-align: left;">
            Fast requests do not, so forget averages, use 98 percentiles
            and focus on the remaining 2% instead.
          </div>
          <p>
          </p>

        </div>

        <aside data-markdown class="notes">
          However, while problematic requests like these are only a tiny
          fraction of our total traffic, in some ways they have the biggest
          impact on our users.
          
          Requests that are significantly faster than the average don't hurt
          anyone, but those significantly slower than the average are the
          ones that break pages, API clients and evidently frustrate users to
          the point that publicly rant about it.

          Worse, some requests can literally run forever when stuck in an
          infinite loop or deadlock. With every hit, they tie up one of your
          worker threads or processes until none are left to service other
          requests, essentially taking out your site.

          To prevent this doom scenario, many webservers, ours included, have a
          builtin watchdog that kills long running requests. Gunicorn defaults
          to 30 seconds after which it hard-kills the worker process. It sends
          a KILL signal equivalent to a "kill -9". Programs cannot intercept this
          signal and so it always works.

          As a consequence, no meaningful statistics can be collected for these
          requests, making them pretty much invisible. We can't tell how long
          they really would have run if they hadn't been killed, nor can we tell
          what they were stuck on.
          
          However, it are these
          requests that frustrate users the most and it are these requests that most clearly demonstrate where you need to
          direct your attention, we needed a way to make them visible.
        </aside>
      </section>


      <section>
        <h2>Logging timeouts</h2>

<pre><code data-trim>import signal

def handler(*args):
    raise Exception("Request timed out")

signal.signal(signal.SIGALRM, handler)

class WsgiMiddleware(object):
    def __init__(self, app):
        self.app = app

    def __call__(self, environ, start_response):
        signal.setitimer(signal.ITIMER_REAL, 28)
        try:
            return self.app(environ, start_response)
        finally:
            signal.setitimer(signal.ITIMER_REAL, 0)
</code></pre>

        <p class="fragment">Full tracebacks of hotspots in Sentry</p>

        <aside data-markdown class="notes">
          What we did was we scheduled an alarm signal at the start of every request
          and cancel the timer when the request is done.
          This alarm signal tells the operating system's kernel, this goes beyond Python, to interrupt our process 28
          seconds after the start of the request, no matter what it was doing and invoke our handler method,
          where we regain control over it.

          Whether it the process was blocked on IO, stuck in a deadlock, or busy
          performing a crazy number of database queries, 28 seconds
          after the start of the request, just before the webserver would
          otherwise kill us, our handler would get invoked and raise
          a normal Python-level exception.

          This unanticipated and uncaught exception deliberately breaks the
          request. It would have crashed anyway when the webserver killed it
          2 seconds later, but now it fails gracefully, with all the details,
          including the exception's stacktrace, getting logged through the
          normal channels. In our case that includes Sentry.
          
          -FRAGMENT-

          With the biggest performance bottlenecks now getting logged properly,
          the true scale of the problem becomes clear.
          And the stacktraces that get logged as part of that include all stack
          variables, pointing us straight to the problematic code.
        </aside>
      </section>


      <section>
        <div>
          GET /api/1.0/repositories/m_eide/nav-maintenance-django/changesets
<pre><code>RequestTimeoutError
  File "bitbucket/apps/api/v10/handlers.py", line 3288, in read
    history = list(repo.history)
  File "orochi/hg.py", line 1188, in __len__
    return len(self._repo)
  File "mercurial/localrepo.py", line 239, in __len__
    return len(self.changelog)
  File "mercurial/scmutil.py", line 897, in __get__
    entry.obj = self.func(obj)
  File "mercurial/localrepo.py", line 197, in changelog
    c = changelog.changelog(self.sopener)
  File "mercurial/changelog.py", line 115, in __init__
    revlog.revlog.__init__(self, opener, "00changelog.i")
  File "mercurial/revlog.py", line 241, in __init__
    i = f.read()
  File "interruptingcow/__init__.py", line 56, in handler
    raise exception</code></pre>

          <span style="color: rgb(220, 220, 220); font-family: monospace; text-align: left; white-space: pre-wrap;">list(repo.history) </span>&nbsp;does not scale well!
        </div>
        <aside data-markdown class="notes">
          After we installed the signal handler, this is one of the timeouts that started appearing on our Sentry
          dashboard.
            
          This is part of the stacktrace of a long-running interrupted request on our commit listing API.
          This returns a paginated list of all the commits in a repository.
          
          The pagination is offset based. The client has to explicitly provide
          a starting point and a page size for every request. Now to help the
          client determine when they have reached the last page, each response
          also includes a count of the total number of commits in the
          repository.

          To determine the total number of commits, this code naively loads all
          commits into a Python list in memory and then looks at
          the length of that list. While it doesn't include any diffs or content, listing commits is not cheap and takes longer
          the more commits there are, to the point that it times out.

          If we insist on including the total commit count, we *have* to find a
          cheaper way to get to it. In Mercurial that is actually pretty easy
          as all commits are sequentially numbered.
          Unfortunately, for Git the only way to find the total number of
          commits is to just count them one by one and since that can take a
          very long time, we have no choice but to drop this information.

          We have since written a newer version of this API, whose pagination 
          does not rely on offsets and counts. Instead each response contains a
          link to the next page. The final page simply does not have this link.
        </aside>
      </section>


      <section>
        <h2>Solution? Simple. just:</h2>

        <div>
          <br>
        </div>

        <ul>
          <li>Rewrite each hotspot to run in constant time</li>
          <li>Leads to predictable, bounded max runtime</li>
          <li>Fixed upper bound is your new 100 percentile</li>
        </ul>
        <aside data-markdown class="notes">
          At this point all we need to do is refactor every single timeout that shows
          up such that it always runs in constant time.

          If this approach is consistently taken, all code paths should ultimately
          end up with a predictable execution time that has a fixed upper
          bound. This deterministic upper bound becomes the new 100 percentile
          and there will never be any performance issues again.
        </aside>
      </section>


      <section>
        <h2>Easier said than done</h2>
        <div><br></div>

        <ul>
          <li>Legacy/bad code often resists refactoring</li>
          <li class="fragment">Dependencies hard to fix</li>
          <li class="fragment">Environmental issues (flushed caches, maintenance)</li>
          <li class="fragment">Unpredictable input<br>
            <pre class="fragment"><code>re.match(r'^(a+)+$',
         'aaaaaaaaaaaaaaaaaaaaaaaaaaaab')</code></pre>
          </li>
        </ul>

        <aside data-markdown class="notes">
          Great! Except of course, not everything is that straightforward.
          
          Sometimes, removing a bad area in your code requires refactoring of large chunks of
          other code and cost a great deal of time, especially when it affects interfaces between independent parts
          of your application.
          
          -FRAGMENT-
          It becomes worse still when the problem is in a library you depend on. If your fixes requires
          incompatible changes to its public interface it might be very difficult for your contribution
          to get accepted, more so when your use case is not considered a common one.
          
          Nowadays most libraries are open source at least, but what if you're not able to modify them? Or they're
          written in an obscure language? All these things can make it prohibitively expensive to
          properly address an issue.
          
          Constant runtime might also simply not be in the cards for some libraries. Regular expressions
          for instance can exhibit widely varying runtime performance, which is hard to predict.
          
          -FRAGMENT-
          To keep things fast, we use quite a bit of caching and we rely quite
          heavily on memcached. However, we do not version our cache keys,
          which means that we have to flush all our caches whenever we deploy.
          As you can imagine, this triggers a short, but sharp spike in load
          and timeouts.

          Luckily we can fix this by versioning our cache keys, but there are
          other external events that can have similar effects on load and
          timeouts.

          Automated infrastructure housekeeping jobs like expensive backups,
          maintenance or hardware failures can be a source of problems that
          are hard to fix in code.
          
          -FRAGMENT-
          Though, possibly the biggest issue for us is processing unpredictable
          input. One example are people who think it's a
          good idea to store 30GB worth of Photoshop files in a Git repo.
          Another example is our use of regular expressions to automatically
          linkify content.
          We try to be smart about detecting mentions of other users, commit hashes, issue keys and pull requests in
          commit messages, issue descriptions, pull request comments and virtually any piece of user
          provided content and turn them into hyperlink.
          
          This matching is done through regular expressions, which is a pretty big performance risk. We
          even allow users to provide their own custom regular expressions so they can create their own
          integrations with external products and services, further increasing the risk of abuse or
          accidental misuse.
          
          -FRAGMENT-
          This seemingly innocuous example for instance will run longer than this talk.
          
          So while the strategy of making everything run in constant time
          sounds great, it's incredibly hard to do so and still manage to build
          an interesting application, requiring a disproportional investment in
          what accounts for only a tiny fraction of your site's traffic.
          
          So instead we need to look for a pragmatic approach that can give us some control over
          unexpected execution times when it's impossible to changing existing code or functionality.
          
          Having been confronted with many of these issues, it became clear that in many cases it would have
          been ok to interrupt a long running request, skip over the problematic portion and render
          a partial result, instead of blowing up, or as a sledgehammer approach, removing functionality that worked fine 99% of the
          time.
        </aside>
      </section>

    
      <section>
        <h2>Interruptingcow</h2>

        <pre class="fragment"><code>$ python
&gt; from interruptingcow import timeout
&gt; with timeout(2, RuntimeError):
&gt;     while True:
&gt;         pass
Traceback (most recent call last):
  File "&lt;stdin>", line 4, in &lt;module>
  File ".../interruptingcow/__init__.py", line 56, in handler
    raise exception
RuntimeError
</code></pre>
        <div class="fragment">
          <pre><code>from interruptingcow import timeout, Quota

quota = Quota(1.0)
try:
    with timeout(20.0, OuterTimeout):
        try:
            with timeout(quota, InnerTimeout):
                try_the_expensive_thing_first()
        except InnerTimeout:
            do_the_cheap_alternative_instead()
except OuterTimeout:
    print 'Program as a whole failed to return in 20 secs'
</code></pre>
        </div>
        <aside data-markdown class="notes">
          We decided to follow up on this and changed our alarm signal handler into
          a generic library that can be used to time-box arbitrary chunks of code at any
          level of the stack. We called it Interruptingcow and here's what it looks like.

          Here I break out of a busy loop after 2 seconds, raising a RuntimeError.

          Timeouts are reentrant which means you can have nested timeouts like
          this.

          -FRAGMENT-

          Here we have a large timeout wrapping a smaller timeout. The inner
          timeout time boxes a potentially expensive operation and provides
          a cheaper alternative version, too.

          Interval values can be simple floats, but you can also use quota
          objects. A quota represents a particular amount of time that can be
          shared boxes.
          Each invocation can only use whatever is left in the quota. If all
          time is used up, further attempts to use it will immediately raise
          their timeout exception.
        </aside>
        
      </section>
      
      
      <section>
        <h2>scalable content linkification</h2>
        <div>
            <br>
        </div>
        <pre><code>def replace(doc, pattern, tmpl):
    try:
        m = pattern.search(doc)
        if m is not None:
            head = doc[:m.start()] + tmpl.format(m.groups())
            tail = doc[m.end():]
            return head + replace(tail, pattern, tmpl)
    except TimeoutException:
        pass
    return doc

with timeout(.1, TimeoutException):
    print replace(doc, re.compile(r'[\da-f]{7,40}'),
                  '&lt;a href="commits/{0}">{0}&lt;/a>')
</code></pre>
        <ul>
            <li>Iteratively linkifies commit hashes until time runs out</li>
        <li>Safely runs user-provided patterns</li>
        </ul>
        
        <aside data-markdown class="notes">
            Now remember I said that we apply regular expressions to commit messages,
            issue comments, etc to automatically turn usernames, commit hashes and
            other known patterns into hyperlinks. And that we even allow users to
            provide custom regexs to create links to anything they like.
            
            To achieve this, we applied timeouts in such a way that matches are
            substituted one by one, util we run out of time. If the input document is
            very big, or the regexs expensive, some unlinked items may remain.
            
            The code here is a simplified version of how we implemented this.
        </aside>
      </section>

      
      <section>
        <h2>django-timelimit</h2>
        <pre><code style="max-height: 500px">{% load timelimit %}
&lt;table class="commit-list">
  &lt;tr>
    &lt;th class="author">Author&lt;/th>
    &lt;th class="message">Message&lt;/th>
  &lt;/tr>
  {% for commit in commit_list %}
    &lt;tr>
      &lt;td class="author">{{ commit.author }}&lt;/td>
      &lt;td class="description">{{ commit.desc }}&lt;/td>
      {% timelimit diffstat_quota %}
        &lt;td class="diffstat">{% diffstat commit %}&lt;/td>
      {% else %}
        &lt;td class="note">diffstat not available&lt;/td>
      {% endtimelimit %}
    &lt;/tr>
  {% endfor %}
&lt;/table>
</code></pre>
        <ul>
          <li class="fragment">Share time intervals among multiple timeouts<br>
            <pre><code>diffstat_quota = interruptingcow.Quota(1.0)</code></pre>
          </li>
        </ul>
        <aside data-markdown class="notes">
          As much of Bitbucket runs on Django we've also written a custom template
          tag for using interrupts straight in Django templates.
          
          The timelimit tag timeboxes its body and will render its else-clause
          if it fails to do so in time.
          
          Here it is used inside a loop, listing properties for a bunch of
          commits. For each commit the number of lines that it changes is
          computed and displayed. However, the time it takes to compute a commit's
          diffstat is related to its size and therefor very unpredictable and
          we only want to spend a limited amount of time. 
          
          -FRAGMENT-
          
          We timebox inside a loop here, allocating our time interval as a
          Quota object so that we can guarantee that the total amount of time
          spent on diffstat computation will never exceed our configured maximum,
          regardless of the number of loop iterations.
        </aside>
      </section>

      <section>
        <h2>Opportunities</h2>

        <ul>
          <li class="fragment">Works with legacy code</li>
          <li class="fragment">Generic solution to different problems</li>
          <li class="fragment">Optimistic approach (EAFP vs LBYL)</li>
          <li class="fragment">Adapts to server load</li>
        </ul>
        <aside data-markdown class="notes">
          I'm not advocating you should wrap everything in timeouts. Not
          every problem lends itself to it. Sometimes there is simply no useful
          degraded or partial representation.
          
          However, the point I want to make is that the best way to guarantee
          responsive web apps is to not have any code with dynamic,
          unpredictable execution time and there are many ways to help with
          this.
          
          This is a very hard problem and probably something that many of us,
          myself included, will continue to face throughout our careers as developers. There
          is no one-size-fits-all solution and we should continue to be smart
          about it.
          
          We should still refactor bad code when possible. Don't make redundant
          database queries.
          
          Always apply pagination.
          
          <!--When performing IO, use sensible read and write timeouts. When you-->
          <!--have to use any kind of locking, whether they be file locks,-->
          <!--threading mutexes, or implicit table or rows locks during a database-->
          <!--transaction, release them as soon as you're done.-->
          
          Even drop functionality for which the execution time is related to
          external factors you don't control.
          
          However, interrupt-driven time-boxing can add to this tool chest,
          and it offers some unique properties:
          
          -FRAGMENT-
          It works with existing code and libraries. Stuff for which
          refactoring is prohibitively expensive. Git's diffstat calculation is
          an example of this.
          
          -FRAGMENT-
          Offers a generic approach to different kinds of bottlenecks, whether
          they're IO- or CPU-bound.
          
          -FRAGMENT-
          It allows for an optimistic approach where unpredictable code does
          not have to be banished altogether, but can continue to be used safely,
          gracefully degrading when necessary. This allows us to offer custom
          linkification.
          
          -FRAGMENT-
          Finally, time-based programming has the interesting characteristic
          that it reacts well under high load. When high server load causes
          programs to run more slowly, time-boxing helps prevent a buildup
          of pending jobs and requests and response times do not suffer.
        </aside>
      </section>

      <section>
        <h2 style="margin-bottom: 100px;">Summary</h2>
        <ul>
          <li class="fragment">Page render times highly dependent on runtime factors</li>
          <li class="fragment">Page timeouts have a disproportionally large impact</li>
          <li class="fragment">Refactor, pre-compute, paginate, remove functionality, etc</li>
          <li class="fragment">Time-box expensive code with cheap fallback</li>
        </ul>
        <p class="fragment" style="margin-top: 100px;"><em>If it ain't fast, you ain't done</em></p>
        
        <aside data-markdown class="notes">
          That's all I have. And so to summarize;
          
          Page render times often fluctuate as they are almost always dependent
          on runtime factors. Most request will be ok, some will be very fast
          and some will be so slow that things break.
          
          The average and fast pages don't bother anyone, but it's those few
          slow pages that give you a bad name.
          
          Always be mindful of performance. When designing new code, make sure
          that it will scale properly.
          
          When everything else fails, time-box your code.
        </aside>
      </section>
      
      <section>
        <ul style="margin-top: 100px;">
          <li><b>Interruptingcow</b> &mdash; time-box arbitrary Python code<br>
            <a href="https://bitbucket.org/evzijst/interruptingcow">bitbucket.org/evzijst/interruptingcow</a></li>
          <li><b>django-timelimit</b> &mdash; time-box Django template fragments<br>
            <a href="https://bitbucket.org/evzijst/django-timelimit">bitbucket.org/evzijst/django-timelimit</a></li>
        </ul>
        <p style="margin-top: 100px;">Slides at:</p>
            <a href="http://evzijst.bitbucket.org/pycon.au/index.html">evzijst.bitbucket.org/pycon.au</a>
            <p><a href="https://twitter.com/erikvanzijst">@erikvanzijst</a></p>
      </section>
    </div>

      </div>

		<script src="lib/js/head.min.js"></script>
		<script src="js/reveal.min.js"></script>

		<script>

			// Full list of configuration options available here:
			// https://github.com/hakimel/reveal.js#configuration
			Reveal.initialize({
				controls: true,
				progress: true,
				history: true,
				center: true,

				theme: Reveal.getQueryHash().theme, // available themes are in /css/theme
				transition: Reveal.getQueryHash().transition || 'default', // default/cube/page/concave/zoom/linear/fade/none

				// Optional libraries used to extend on reveal.js
				dependencies: [
					{ src: 'lib/js/classList.js', condition: function() { return !document.body.classList; } },
					{ src: 'plugin/markdown/marked.js', condition: function() { return !!document.querySelector( '[data-markdown]' ); } },
					{ src: 'plugin/markdown/markdown.js', condition: function() { return !!document.querySelector( '[data-markdown]' ); } },
					{ src: 'plugin/highlight/highlight.js', async: true, callback: function() { hljs.initHighlightingOnLoad(); } },
					{ src: 'plugin/zoom-js/zoom.js', async: true, condition: function() { return !!document.body.classList; } },
					{ src: 'plugin/notes/notes.js', async: true, condition: function() { return !!document.body.classList; } }
					// { src: 'plugin/search/search.js', async: true, condition: function() { return !!document.body.classList; } }
					// { src: 'plugin/remotes/remotes.js', async: true, condition: function() { return !!document.body.classList; } }
				]
			});

		</script>

	</body>
</html>

<!doctype html>
<html lang="en">

	<head>
		<meta charset="utf-8">

		<title>PyCon AU -- Interrupt-Driven Programming</title>

		<meta name="description" content="This talk explores the challenges of ensuring responsiveness of applications under varying conditions like suddenly increased load, code regressions and problematic user data that reveal code paths with unusually high time complexity.">
		<meta name="author" content="Erik van Zijst">

		<meta name="apple-mobile-web-app-capable" content="yes" />
		<meta name="apple-mobile-web-app-status-bar-style" content="black-translucent" />

		<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">

		<link rel="stylesheet" href="css/reveal.min.css">
		<link rel="stylesheet" href="css/theme/default.css" id="theme">

		<!-- For syntax highlighting -->
		<link rel="stylesheet" href="lib/css/zenburn.css">

		<!-- If the query includes 'print-pdf', use the PDF print sheet -->
		<script>
			document.write( '<link rel="stylesheet" href="css/print/' + ( window.location.search.match( /print-pdf/gi ) ? 'pdf' : 'paper' ) + '.css" type="text/css" media="print">' );
		</script>

		<!--[if lt IE 9]>
		<script src="lib/js/html5shiv.js"></script>
		<![endif]-->
	</head>

	<body>
		<div class="reveal">
			<!-- Any section element inside of this container is displayed as a slide -->
			<div class="slides">

      <section>
        <h1>Interrupt-driven programming</h1>

        <div id="erik-van-zijst">
          <p>Erik van Zijst</p>
          <p>
            <a href="https://twitter.com/erikvanzijst">@erikvanzijst</a>
          </p>
          <p>
            <a href="https://bitbucket.org/evzijst">bitbucket.org/evzijst</a>
          </p>
        </div>
      </section>


      <section>
        <h2>
          <img
            src="tweet.png" style="font-size: 75.96px; width: 574px;">
          <br>
        </h2>
      </section>


      <section>
        <h2>Really?</h2>
        <div>
          <img src="bitbucket_performance.png" style="height: 285px;">
        </div>
        <div>
          <img src="github_performance.png" style="height: 170px;">
        </div>
        <div>123ms vs 139ms &mdash; Averages are misleading</div>

        <aside class="notes">
          A quick comparison of the 2 sites' average response time provides no
          basis for the big discrepancy.
          Quick inspection reveals that the client relies on a small number of
          APIs, of which one performs exceptionally poorly.

          Due to the APIs low traffic, its poor performance has almost no affect
          on the average, which goes to show that averages are a misleading metric, as our
          busiest APIs have been also been tuned the most.
        </aside>
      </section>


      <section>
          <h3>
            Slow requests have a big impact
          </h3>
        <div>

          <ul>
            <li>Frustrate users, timeouts</li>
            <li>Break API clients</li>
            <li>Rants on Twitter</li>
          </ul>
          <div style="text-align: left;">
            <br>
          </div>
          <div style="text-align: left;">
            Fast requests do not, so forget averages, use 98 percentiles
            and focus on the 2% instead.
          </div>
          <p>
          </p>

        </div>

        <aside class="notes">
          However, while problematic requests are only a tiny fraction of your
          total traffic, they have
          the biggest impact on usability. Requests that are significantly
          faster than the average don't pose any
          problems, but those significantly slower than the average are the ones
          that break pages and API clients.

          Worse, some requests can literally run forever when stuck in an
          infinite loop or deadlock. With every
          hit, they tie up one of your worker threads or processes until none
          are left to service other
          requests, essentially taking out your site.

          To prevent this doom scenario, many webservers, ours included, have a
          builtin watchdog that kills
          long running requests. Gunicorn defaults to 30 seconds after which it
          SIGKILLs the worker process.

          As a consequence, no meaningful statistics can be collected for these
          requests, making them all but
          invisible. Since the longest running requests most clearly demonstrate
          where you need to direct your
          attention, we needed a way to make them visible.
        </aside>
      </section>


      <section>
        <h2>Log timeouts</h2>

<pre><code data-trim>import signal

def handler(*args):
    raise Exception("Request timed out")

signal.signal(signal.SIGALRM, handler)

class WsgiMiddleware(object):
    def __init__(self, app):
        self.app = app

  def __call__(self, environ, start_response):
      signal.setitimer(signal.ITIMER_REAL, 28)
      try:
          return self.app(environ, start_response)
      finally:
          signal.setitimer(signal.ITIMER_REAL, 0)
</code></pre>

        <p class="fragment">Full tracebacks of hotspots in Sentry.</p>

        <aside class="notes">
          What we did was we scheduled an alarm signal for every request,
          telling the operating system's kernel to interrupt our process in 28
          seconds, no matter what it was doing and invoke our handler method.

          Whether it was waiting for IO, or stuck in a deadlock, 28 seconds
          after the start of the request, just before the webserver would
          otherwise kill the request, our handler would get invoked and raise
          a normal Python-level exception.

          This unanticipated and uncaught exception then causes the request to
          fail normally, logging the event through the normal channels. In our
          case that includes Sentry.
          
          -FRAGMENT-

          Not only can we now identify the biggest performance bottlenecks, but
          the stacktraces including all stack variables, point us straight to
          the problematic code.
        </aside>
      </section>
      
      
      <section>
    <h2>Simple, just:</h2>
<div>
<br>
</div>

<ul>
<li>Rewrite each hotspot to run in constant time</li>
<li>Leads to predictable, bounded max runtime</li>
<li>Fixed upper bound is your new 100 percentile</li>
</ul>
<aside class="notes">
    At this point all we need to do is refactor hotspots with code that always runs in constant time.
    
    When this approach is consistently taken, all code paths ultimately end up with a predictable
    execution time that has a fixed upper threshold. This deterministic upper bound becomes the new
    100 percentile.
</aside>
</section>
<section>
<div>
GET /api/1.0/repositories/m_eide/nav-maintenance-django/changesets
<pre><code>RequestTimeoutError

  File "piston/resource.py", line 174, in checked_meth
    return meth(*args, **kwargs)
  File "piston/utils.py", line 153, in wrap
    return f(self, request, *args, **kwargs)
  File "bitbucket/apps/api/v10/handlers.py", line 3288, in read
    history = list(repo.history)
  File "orochi/hg.py", line 1188, in __len__
    return len(self._repo)
  File "mercurial/localrepo.py", line 239, in __len__
    return len(self.changelog)
  File "mercurial/scmutil.py", line 897, in __get__
    entry.obj = self.func(obj)
  File "mercurial/localrepo.py", line 197, in changelog
    c = changelog.changelog(self.sopener)
  File "mercurial/changelog.py", line 115, in __init__
    revlog.revlog.__init__(self, opener, "00changelog.i")
  File "mercurial/revlog.py", line 241, in __init__
    i = f.read()
  File "interruptingcow/__init__.py", line 56, in handler
    raise exception</code></pre>

<span style="color: rgb(220, 220, 220); font-family: monospace; text-align: left; white-space: pre-wrap;">list(repo.history) </span>&nbsp;does not scale well</div>
<aside class="notes">
    After we installed the signal handler, this is one of the timeouts that started appearing on our Sentry
    dashboard.
    
    This is the interrupted stacktrace of a long-running request on our commit listing API. To avoid having to
    read through the entire repository, the response is paginated. The pagination here is
    offset-based and the response also includes a count of the total number of commits in the repository. This
    is to help users determine when they have reached the last page.
    
    To determine the total number of commits, this code loads all commits into a Python list and then looks at
    the length of that list. While it doesn't read any content, listing commits is not cheap and takes longer
    the more commits there are, to the point that it times out.
    
    Unfortunately, for Git the only way to find the total number of commits is to just count them one by one
    and so we have to drop this information.
    
    We have since written a newer version of this API, whose pagination is not offset-based, but uses links
    embedded in the response.
</aside>
</section>
<section>
    <h2>Easier said than done</h2>
<div>intermittent infrastructure issues</div>
<div>severe lock contention</div>
<div>unpredictable input (4GB blob)</div>
<div>problematic libraries (regex?)</div>
<div>
    <br>
</div>

<aside class="notes">
    Great! Except of course, not everything is that straightforward.
    
    Sometimes, removing a problematic area in your code requires refactoring of large chunks of
    other code and cost a great deal of time, especially when it affect interfaces between independent parts
    of your application.
    
    It becomes worse still when the problem is in a library you depend on. If your fixes require
    incompatible changes to its public interface it might be very difficult for your contribution
    to get accepted, more so when your use case is not considered a common one.
    
    Nowadays most libraries are open source, but what if you're not able to modify them? Or they're
    written in an obscure language? All these things can make it prohibitively expensive to
    properly address an issue.
    
    Constant runtime might also simply not be in the cards for some libraries. Regular expressions
    for instance can exhibit widely varying runtime performance.
    
    Another, completely different class of problems we've seen is due to lock contention. Transactional
    database updates can hold up other queries and updates and as your site becomes busier, the effects
    of contention become more severe. A request that may have been instant at one point, may be substantially
    slower or even time out at another time.
    
    We also see a spike in timeouts right after we deploy. One contributing factor here is that since
    our caches are not versioned, we have to flush our memcached servers after every deploy. This leads
    to a short but sharp load spike, affecting nearly everything on the site. Automated infrastructure
    housekeeping jobs like expensive backups, maintenance or hardware failures can have similar effects
    on performance.
    
    Though, possibly the biggest issue for us is processing unpredictable input. Bitbucket tries to
    be smart about detecting mentions of other users, commit hashes, issue keys and pull requests in
    commit messages, issue descriptions, pull request comments and virtually any piece of user
    provided content.
    
    This matching is done through regular expressions, which is a pretty big performance risk. We
    even allow users to provide their own custom regular expressions so they can create their own
    integrations with external products and services, further increasing the risk of abuse or
    accidental misuse.
    
    This somewhat contrived example for instance will run longer than this talk.
    
    So while the strategy of making everything run in constant time sounds great, it's incredibly
    hard to do so, requiring a disproportional investment in what accounts for only a tiny fraction
    of your site's traffic.
    
    So instead we need to look for a pragmatic approach that can give us some control over
    unexpected execution times when it's impossible to changing existing code or functionality.
    
    Having been confronted with many of these issues, it became clear that in many cases it would have
    been ok to interrupt a long running request, skip over the problematic portion and render
    a partial result, instead of blowing up, or removing functionality that works fine 99% of the
    time.
    
</aside>
</section>

    
<section>
<h2>Interruptingcow</h2>

<pre><code>$ python
&gt; from interruptingcow import timeout
&gt; with timeout(2, RuntimeError):
&gt;     while True:
&gt;         pass
Traceback (most recent call last):
  File "<stdin>", line 4, in <module>
  File ".../interruptingcow/__init__.py", line 56, in handler
    raise exception
RuntimeError
</code></pre>

<pre><code>from interruptingcow import timeout

class RequestTimeout(Exception): pass

class TimeboxedMiddleware(object):
    def __init__(self, app):
        self.app = app
    
    @timeout(28, RequestTimeout)
    def __call__(self, environ, start_response):
        self.app(environ, start_response)
</code></pre>
<ul>
    <li>Interrupt any code path by raising custom exceptions</li>
</ul>

<aside class="notes">
    We decided to follow up on this and changed our alarm signal handler into
    a generic library that can be used to timebox arbitrary chunks of code at any
    level of the stack. We called it Interruptingcow and here's what it looks like.
    
    Here I break out of a busy loop after 2 seconds, raising a RuntimeError.
    
    It's also a decorator, which simplifies our timeout middleware.
    
    Because it's reentrant and supports arbitrary nesting of independant timeouts,
    we freely use it in any part of our code, using unique exceptions and catching
    them in those cases where we are able to perform a cheaper, alternative
    action.
</aside>

</section>
<section>
<h2>scalable content linkification</h2>
<div>
    <br>
</div>
<pre><code>
def replace(doc, pattern, tmpl):
    try:
        m = pattern.search(doc)
        if m is not None:
            head = doc[:m.start()] + tmpl.format(m.groups())
            tail = doc[m.end():]
            return head + replace(tail, pattern, tmpl)
    except TimeoutException:
        pass
    return doc

with timeout(.1, TimeoutException):
    print replace(doc, re.compile(r'[\da-f]{7,40}'),
                  '<a href="commits/{0}">{0}</a>')
</code></pre>
<ul>
    <li>Iteratively linkifies commit hashes until time runs out</li>
<li>Safely runs user-provided patterns</li>
</ul>

<aside class="notes">
    Now remember I said that we apply regular expressions to commit messages,
    issue comments, etc to automatically turn usernames, commit hashes and
    other known patterns into hyperlinks. And that we even allow users to
    provide custom regexs to create links to anything they like.
    
    To achieve this, we applied timeouts in such a way that matches are
    substituted one by one, util we run out of time. If the input document is
    very big, or the regexs expensive, some unlinked items may remain.
    
    The code here is a simplified version of how we implemented this.
</aside>
</section>
    
<section>
<h2>django-timelimit</h2>
<pre>{% load timelimit %}
<table class="commit-list">
  <tr>
    <th class="author">{% trans "Author" %}</th>
    <th class="message">{% trans "Message" %}</th>
  </tr>
  {% for commit in commit_list %}
    <tr>
      <td class="author">{{ commit.author }}</td>
      <td class="description">{{ commit.desc }}</td>
      {% timelimit quota %}
        <td class="diffstat">{% diffstat commit %}</td>
      {% else %}
        <td class="note">diffstat not available</td>
      {% endtimelimit %}
    </tr>
  {% endfor %}
</table>
</pre>
<aside class="notes">
    As much of Bitbucket runs in Django we've also written a custom template
    tag for using interrupts straight in Django templates.
</aside>
</section>
<section>
    <h2>Nesting</h2>

<aside class="notes">
    It is reentrant and supports arbitrary nesting of independant timeouts.
    This allows us to 
</aside>
</section>
</div>

        
        
      </div>

		<script src="lib/js/head.min.js"></script>
		<script src="js/reveal.min.js"></script>

		<script>

			// Full list of configuration options available here:
			// https://github.com/hakimel/reveal.js#configuration
			Reveal.initialize({
				controls: true,
				progress: true,
				history: true,
				center: true,

				theme: Reveal.getQueryHash().theme, // available themes are in /css/theme
				transition: Reveal.getQueryHash().transition || 'default', // default/cube/page/concave/zoom/linear/fade/none

				// Optional libraries used to extend on reveal.js
				dependencies: [
					{ src: 'lib/js/classList.js', condition: function() { return !document.body.classList; } },
					{ src: 'plugin/markdown/marked.js', condition: function() { return !!document.querySelector( '[data-markdown]' ); } },
					{ src: 'plugin/markdown/markdown.js', condition: function() { return !!document.querySelector( '[data-markdown]' ); } },
					{ src: 'plugin/highlight/highlight.js', async: true, callback: function() { hljs.initHighlightingOnLoad(); } },
					{ src: 'plugin/zoom-js/zoom.js', async: true, condition: function() { return !!document.body.classList; } },
					{ src: 'plugin/notes/notes.js', async: true, condition: function() { return !!document.body.classList; } }
					// { src: 'plugin/search/search.js', async: true, condition: function() { return !!document.body.classList; } }
					// { src: 'plugin/remotes/remotes.js', async: true, condition: function() { return !!document.body.classList; } }
				]
			});

		</script>

	</body>
</html>
